{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "279c096d",
   "metadata": {},
   "source": [
    "# ROME-Based Language Model editing\n",
    "\n",
    "This notebook demonstrates how to edit a language model using the **ROME (Rank-One Model Editing)** method.\n",
    "\n",
    "Evaluation parameters:\n",
    "Efficacy, Paragraph, Neighborhood\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce1537c",
   "metadata": {},
   "source": [
    "## Overview\n",
    "See readme.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb6453e",
   "metadata": {},
   "source": [
    "## 0. Install Dependencies\n",
    "Run the following cell to install required packages:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1179f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run if needed\n",
    "# !pip install transformers torch rome\n",
    "# !pip install datasets\n",
    "# Pandas is required\n",
    "# Numby is required"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8f4a7a",
   "metadata": {},
   "source": [
    "## 1. Load Pretrained Model\n",
    "Here we load GPT-Neo-125M using Hugging Face Transformers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fcac183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: EleutherAI/gpt-neo-125M\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_name = \"EleutherAI/gpt-neo-125M\"  \n",
    "print(f\"Loading model: {model_name}\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "#model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f83011",
   "metadata": {},
   "source": [
    "## 2. Load CounterFact Dataset\n",
    "Load the CounterFact dataset from Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18ad0d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CounterFact dataset...\n",
      "Dataset loaded: 19728 examples\n",
      "\n",
      "Dataset columns: ['case_id', 'pararel_idx', 'requested_rewrite', 'paraphrase_prompts', 'neighborhood_prompts', 'attribute_prompts', 'generation_prompts']\n",
      "\n",
      "First example:\n",
      "{'prompt': 'The mother tongue of {} is', 'relation_id': 'P103', 'subject': 'Danielle Darrieux', 'target_new': {'id': 'Q1860', 'str': 'English'}, 'target_true': {'id': 'Q150', 'str': 'French'}}\n"
     ]
    }
   ],
   "source": [
    "# Install datasets library if needed in part 0\n",
    "\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CounterFact dataset\n",
    "print(\"Loading CounterFact dataset...\")\n",
    "dataset = load_dataset(\"azhx/counterfact\", split=\"train\")\n",
    "print(f\"Dataset loaded: {len(dataset)} examples\")\n",
    "\n",
    "# Convert to pandas for easier manipulation\n",
    "df = dataset.to_pandas()\n",
    "print(f\"\\nDataset columns: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst example:\")\n",
    "print(df.iloc[0]['requested_rewrite'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b33a5d",
   "metadata": {},
   "source": [
    "## 3. Evaluate Model Performance\n",
    "Evaluate the model on key metrics: Efficacy, Paragraph, and Neighborhood scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b28b5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on default example (France -> capital -> Lyon)\n",
      "Note: Re-run this cell after defining edit parameters to evaluate your specific edit\n",
      "--------------------------------------------------\n",
      "Efficacy Score: -25.5820\n",
      "  (Higher is better - measures if edit was successful)\n",
      "\n",
      "Paragraph Score: 1.0000\n",
      "  (1.0 = fact maintained in generation, 0.0 = not maintained)\n",
      "\n",
      "Neighborhood Score: -25.5615\n",
      "  (Higher is better - measures preservation of unrelated facts)\n",
      "--------------------------------------------------\n",
      "\n",
      "Summary:\n",
      "  Efficacy: -25.5820\n",
      "  Paragraph: 1.0000\n",
      "  Neighborhood: -25.5615\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "def compute_log_probs(model, tokenizer, prompt, target_tokens):\n",
    "    \"\"\"Compute log probabilities for target tokens given a prompt.\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    target_ids = tokenizer(target_tokens, return_tensors=\"pt\", add_special_tokens=False)[\"input_ids\"][0]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits[0, -1, :]  # Last token logits\n",
    "        log_probs = F.log_softmax(logits, dim=-1)\n",
    "        target_log_probs = log_probs[target_ids].sum().item()\n",
    "    \n",
    "    return target_log_probs\n",
    "\n",
    "def efficacy_score(model, tokenizer, subject, relation, new_object):\n",
    "    \"\"\"\n",
    "    Efficacy Score: Measures if the model correctly answers the edited fact.\n",
    "    Higher score = better (model correctly predicts the new object).\n",
    "    \"\"\"\n",
    "    prompts = [\n",
    "        f\"What is the {relation} of {subject}?\",\n",
    "        f\"The {relation} of {subject} is\",\n",
    "        f\"{subject}'s {relation} is\",\n",
    "    ]\n",
    "    \n",
    "    scores = []\n",
    "    for prompt in prompts:\n",
    "        # Compute log probability of the new object\n",
    "        score = compute_log_probs(model, tokenizer, prompt, new_object)\n",
    "        scores.append(score)\n",
    "    \n",
    "    return np.mean(scores)\n",
    "\n",
    "def paragraph_score(model, tokenizer, subject, relation, new_object):\n",
    "    \"\"\"\n",
    "    Paragraph Score: Measures coherence in longer text generation.\n",
    "    Generates a paragraph and checks if it maintains consistency.\n",
    "    \"\"\"\n",
    "    prompt = f\"The {relation} of {subject} is {new_object}.\"\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_length=100,\n",
    "            num_return_sequences=1,\n",
    "            temperature=0.7,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id if tokenizer.eos_token_id is not None else tokenizer.pad_token_id\n",
    "        )\n",
    "    \n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Check if the generated text maintains the fact\n",
    "    # Simple heuristic: check if new_object appears in the generated text\n",
    "    fact_maintained = new_object.lower() in generated_text.lower()\n",
    "    \n",
    "    # Compute perplexity-like score (lower is better for coherence)\n",
    "    # We'll use a simple metric: check if the fact is mentioned\n",
    "    return 1.0 if fact_maintained else 0.0\n",
    "\n",
    "def neighborhood_score(model, tokenizer, subject, relation, new_object):\n",
    "    \"\"\"\n",
    "    Neighborhood Score: Measures if the model maintains performance on \n",
    "    similar but unrelated facts (should not be affected by the edit).\n",
    "    \"\"\"\n",
    "    # Define similar but unrelated facts\n",
    "    neighborhood_prompts = [\n",
    "        (\"Germany\", \"capital\", \"Berlin\"),\n",
    "        (\"Italy\", \"capital\", \"Rome\"),\n",
    "        (\"Spain\", \"capital\", \"Madrid\"),\n",
    "    ]\n",
    "    \n",
    "    scores = []\n",
    "    for subj, rel, obj in neighborhood_prompts:\n",
    "        prompt = f\"What is the {rel} of {subj}?\"\n",
    "        score = compute_log_probs(model, tokenizer, prompt, obj)\n",
    "        scores.append(score)\n",
    "    \n",
    "    return np.mean(scores)\n",
    "\n",
    "# Evaluate the model\n",
    "# Use edit parameters if defined, otherwise use defaults\n",
    "try:\n",
    "    eval_subject = subject\n",
    "    eval_relation = relation\n",
    "    eval_object = new_object\n",
    "    print(f\"Evaluating on edit: {subject} -> {relation} -> {new_object}\")\n",
    "except NameError:\n",
    "    # Default values for initial evaluation (before edit is defined)\n",
    "    eval_subject = \"France\"\n",
    "    eval_relation = \"capital\"\n",
    "    eval_object = \"Lyon\"\n",
    "    print(\"Evaluating on default example (France -> capital -> Lyon)\")\n",
    "    print(\"Note: Re-run this cell after defining edit parameters to evaluate your specific edit\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Efficacy Score\n",
    "efficacy = efficacy_score(model, tokenizer, eval_subject, eval_relation, eval_object)\n",
    "print(f\"Efficacy Score: {efficacy:.4f}\")\n",
    "print(\"  (Higher is better - measures if edit was successful)\")\n",
    "\n",
    "# Paragraph Score\n",
    "paragraph = paragraph_score(model, tokenizer, eval_subject, eval_relation, eval_object)\n",
    "print(f\"\\nParagraph Score: {paragraph:.4f}\")\n",
    "print(\"  (1.0 = fact maintained in generation, 0.0 = not maintained)\")\n",
    "\n",
    "# Neighborhood Score\n",
    "neighborhood = neighborhood_score(model, tokenizer, eval_subject, eval_relation, eval_object)\n",
    "print(f\"\\nNeighborhood Score: {neighborhood:.4f}\")\n",
    "print(\"  (Higher is better - measures preservation of unrelated facts)\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"  Efficacy: {efficacy:.4f}\")\n",
    "print(f\"  Paragraph: {paragraph:.4f}\")\n",
    "print(f\"  Neighborhood: {neighborhood:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d5ed0a",
   "metadata": {},
   "source": [
    "## 4.1 Select facts to edit  \n",
    "Number of edited facts can be edited by changing num_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "488f980f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 100 random facts for editing:\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Fact 1:\n",
      "  Subject: Peak Records\n",
      "  Prompt: The genre played by Peak Records is\n",
      "  Original: jazz\n",
      "  New: fantasy\n",
      "\n",
      "Fact 2:\n",
      "  Subject: Frederik Andersen\n",
      "  Prompt: Frederik Andersen, the\n",
      "  Original: goaltender\n",
      "  New: midfielder\n",
      "\n",
      "Fact 3:\n",
      "  Subject: Ankara Province\n",
      "  Prompt: The capital of Ankara Province is\n",
      "  Original: Ankara\n",
      "  New: Munich\n",
      "\n",
      "Fact 4:\n",
      "  Subject: Caecilius of Elvira\n",
      "  Prompt: Caecilius of Elvira holds the title of\n",
      "  Original: bishop\n",
      "  New: pope\n",
      "\n",
      "Fact 5:\n",
      "  Subject: Politically Incorrect\n",
      "  Prompt: The original language of Politically Incorrect was\n",
      "  Original: English\n",
      "  New: Tamil\n",
      "\n",
      "Fact 6:\n",
      "  Subject: Andor Toth\n",
      "  Prompt: Andor Toth performs on the\n",
      "  Original: violin\n",
      "  New: piano\n",
      "\n",
      "Fact 7:\n",
      "  Subject: Kennin-ji\n",
      "  Prompt: The official religion of Kennin-ji is\n",
      "  Original: Buddhism\n",
      "  New: Christianity\n",
      "\n",
      "Fact 8:\n",
      "  Subject: Zuiderzee\n",
      "  Prompt: Zuiderzee, in\n",
      "  Original: Netherlands\n",
      "  New: Sweden\n",
      "\n",
      "Fact 9:\n",
      "  Subject: Albertus Magnus\n",
      "  Prompt: Albertus Magnus worked in the city of\n",
      "  Original: Cologne\n",
      "  New: London\n",
      "\n",
      "Fact 10:\n",
      "  Subject: Sony Pictures Entertainment Japan\n",
      "  Prompt: Sony Pictures Entertainment Japan, by\n",
      "  Original: Sony\n",
      "  New: Germany\n",
      "\n",
      "Fact 11:\n",
      "  Subject: Apple Filing Protocol\n",
      "  Prompt: Apple Filing Protocol is created by\n",
      "  Original: Apple\n",
      "  New: IBM\n",
      "\n",
      "Fact 12:\n",
      "  Subject: Denmark\n",
      "  Prompt: The capital of Denmark is\n",
      "  Original: Copenhagen\n",
      "  New: Tripoli\n",
      "\n",
      "Fact 13:\n",
      "  Subject: Likkutei Sichos\n",
      "  Prompt: The original language of Likkutei Sichos is\n",
      "  Original: Hebrew\n",
      "  New: Tamil\n",
      "\n",
      "Fact 14:\n",
      "  Subject: James Arness\n",
      "  Prompt: James Arness, who works as\n",
      "  Original: actor\n",
      "  New: composer\n",
      "\n",
      "Fact 15:\n",
      "  Subject: Joel Barlow\n",
      "  Prompt: Joel Barlow's profession is an\n",
      "  Original: poet\n",
      "  New: journalist\n",
      "\n",
      "Fact 16:\n",
      "  Subject: Franz Reuleaux\n",
      "  Prompt: Franz Reuleaux's expertise is\n",
      "  Original: mechanics\n",
      "  New: physician\n",
      "\n",
      "Fact 17:\n",
      "  Subject: Lake Victoria\n",
      "  Prompt: Lake Victoria, called after\n",
      "  Original: Victoria\n",
      "  New: Peter\n",
      "\n",
      "Fact 18:\n",
      "  Subject: Gerakan Pramuka Indonesia\n",
      "  Prompt: Gerakan Pramuka Indonesia was employed in\n",
      "  Original: Indonesia\n",
      "  New: Amsterdam\n",
      "\n",
      "Fact 19:\n",
      "  Subject: La clemenza di Tito\n",
      "  Prompt: The original language of La clemenza di Tito was\n",
      "  Original: Italian\n",
      "  New: Hindi\n",
      "\n",
      "Fact 20:\n",
      "  Subject: Formentera\n",
      "  Prompt: In Formentera, they understand\n",
      "  Original: Spanish\n",
      "  New: Russian\n",
      "\n",
      "Fact 21:\n",
      "  Subject: Jeanna Friske\n",
      "  Prompt: Jeanna Friske is a native speaker of\n",
      "  Original: Russian\n",
      "  New: Dutch\n",
      "\n",
      "Fact 22:\n",
      "  Subject: Vietnam Film Festival\n",
      "  Prompt: Vietnam Film Festival is located in\n",
      "  Original: Vietnam\n",
      "  New: Moscow\n",
      "\n",
      "Fact 23:\n",
      "  Subject: Munich Airport\n",
      "  Prompt: Munich Airport was named for\n",
      "  Original: Munich\n",
      "  New: coffee\n",
      "\n",
      "Fact 24:\n",
      "  Subject: Ottawan\n",
      "  Prompt: What does Ottawan play? They play\n",
      "  Original: disco\n",
      "  New: sitcom\n",
      "\n",
      "Fact 25:\n",
      "  Subject: Binary Synchronous Communications\n",
      "  Prompt: Binary Synchronous Communications, a product created by\n",
      "  Original: IBM\n",
      "  New: Apple\n",
      "\n",
      "Fact 26:\n",
      "  Subject: Ford Star Jubilee\n",
      "  Prompt: Ford Star Jubilee is to debut on\n",
      "  Original: CBS\n",
      "  New: NBC\n",
      "\n",
      "Fact 27:\n",
      "  Subject: Aalog-Alog\n",
      "  Prompt: Aalog-Alog, that was developed in\n",
      "  Original: Philippines\n",
      "  New: Canada\n",
      "\n",
      "Fact 28:\n",
      "  Subject: Phyllis Gotlieb\n",
      "  Prompt: Phyllis Gotlieb holds a citizenship from\n",
      "  Original: Canada\n",
      "  New: Cuba\n",
      "\n",
      "Fact 29:\n",
      "  Subject: Adobe Creative Suite\n",
      "  Prompt: Adobe Creative Suite was created by\n",
      "  Original: Adobe\n",
      "  New: Apple\n",
      "\n",
      "Fact 30:\n",
      "  Subject: Wim Crouwel\n",
      "  Prompt: The native language of Wim Crouwel is\n",
      "  Original: Dutch\n",
      "  New: Swedish\n",
      "\n",
      "Fact 31:\n",
      "  Subject: Princess Ingeborg of Denmark\n",
      "  Prompt: Princess Ingeborg of Denmark died in\n",
      "  Original: Stockholm\n",
      "  New: Lisbon\n",
      "\n",
      "Fact 32:\n",
      "  Subject: Triumph TR7\n",
      "  Prompt: Triumph TR7, created by\n",
      "  Original: Triumph\n",
      "  New: Fiat\n",
      "\n",
      "Fact 33:\n",
      "  Subject: Guangzhou\n",
      "  Prompt: The twin city of Guangzhou is\n",
      "  Original: Manila\n",
      "  New: Chicago\n",
      "\n",
      "Fact 34:\n",
      "  Subject: Anders Sunesen\n",
      "  Prompt: Anders Sunesen speaks the language\n",
      "  Original: Latin\n",
      "  New: Dutch\n",
      "\n",
      "Fact 35:\n",
      "  Subject: North British Locomotive Company\n",
      "  Prompt: North British Locomotive Company is based in\n",
      "  Original: Glasgow\n",
      "  New: Bethlehem\n",
      "\n",
      "Fact 36:\n",
      "  Subject: Google AdSense\n",
      "  Prompt: Google AdSense, a product developed by\n",
      "  Original: Google\n",
      "  New: Microsoft\n",
      "\n",
      "Fact 37:\n",
      "  Subject: Sanlih E-Television\n",
      "  Prompt: Sanlih E-Television, which is located in\n",
      "  Original: Taiwan\n",
      "  New: Ukraine\n",
      "\n",
      "Fact 38:\n",
      "  Subject: Crazy Eddie\n",
      "  Prompt: Crazy Eddie was started in\n",
      "  Original: Brooklyn\n",
      "  New: Scotland\n",
      "\n",
      "Fact 39:\n",
      "  Subject: Larry King\n",
      "  Prompt: Larry King was native to\n",
      "  Original: Brooklyn\n",
      "  New: Denmark\n",
      "\n",
      "Fact 40:\n",
      "  Subject: System Controller Hub\n",
      "  Prompt: System Controller Hub, developed by\n",
      "  Original: Intel\n",
      "  New: Fiat\n",
      "\n",
      "Fact 41:\n",
      "  Subject: Wilhelm Roux\n",
      "  Prompt: Wilhelm Roux works in the area of\n",
      "  Original: anatomy\n",
      "  New: physiology\n",
      "\n",
      "Fact 42:\n",
      "  Subject: Afghanistan Football Federation\n",
      "  Prompt: Afghanistan Football Federation is a member of\n",
      "  Original: FIFA\n",
      "  New: NATO\n",
      "\n",
      "Fact 43:\n",
      "  Subject: Sucker Punch Productions\n",
      "  Prompt: Sucker Punch Productions is owned by\n",
      "  Original: Sony\n",
      "  New: Google\n",
      "\n",
      "Fact 44:\n",
      "  Subject: Michael Urbano\n",
      "  Prompt: Michael Urbano was originally from\n",
      "  Original: Sacramento\n",
      "  New: Calgary\n",
      "\n",
      "Fact 45:\n",
      "  Subject: Henry Corbin\n",
      "  Prompt: Henry Corbin's domain of work is\n",
      "  Original: philosophy\n",
      "  New: physiology\n",
      "\n",
      "Fact 46:\n",
      "  Subject: Frigate Range\n",
      "  Prompt: Frigate Range, in\n",
      "  Original: Antarctica\n",
      "  New: Asia\n",
      "\n",
      "Fact 47:\n",
      "  Subject: Imre Nagy\n",
      "  Prompt: Imre Nagy worked in\n",
      "  Original: Budapest\n",
      "  New: Birmingham\n",
      "\n",
      "Fact 48:\n",
      "  Subject: Jacinto Vera\n",
      "  Prompt: Jacinto Vera has the position of\n",
      "  Original: bishop\n",
      "  New: mayor\n",
      "\n",
      "Fact 49:\n",
      "  Subject: Eduard Marxsen\n",
      "  Prompt: Eduard Marxsen worked in the city of\n",
      "  Original: Hamburg\n",
      "  New: Cologne\n",
      "\n",
      "Fact 50:\n",
      "  Subject: Power Jets\n",
      "  Prompt: The headquarter of Power Jets is located in\n",
      "  Original: Rugby\n",
      "  New: Tehran\n",
      "\n",
      "Fact 51:\n",
      "  Subject: Pavel Datsyuk\n",
      "  Prompt: Pavel Datsyuk, the\n",
      "  Original: hockey\n",
      "  New: baseball\n",
      "\n",
      "Fact 52:\n",
      "  Subject: Mount Discovery\n",
      "  Prompt: Mount Discovery is in\n",
      "  Original: Antarctica\n",
      "  New: Asia\n",
      "\n",
      "Fact 53:\n",
      "  Subject: Samson & Goliath\n",
      "  Prompt: Samson & Goliath premiered on\n",
      "  Original: NBC\n",
      "  New: CBS\n",
      "\n",
      "Fact 54:\n",
      "  Subject: Colby Cameron\n",
      "  Prompt: Colby Cameron plays as\n",
      "  Original: quarterback\n",
      "  New: midfielder\n",
      "\n",
      "Fact 55:\n",
      "  Subject: Dave Winfield\n",
      "  Prompt: What sport does Dave Winfield play? They play\n",
      "  Original: baseball\n",
      "  New: soccer\n",
      "\n",
      "Fact 56:\n",
      "  Subject: Patricia Conroy\n",
      "  Prompt: Patricia Conroy, who holds a citizenship from\n",
      "  Original: Canada\n",
      "  New: Cambodia\n",
      "\n",
      "Fact 57:\n",
      "  Subject: Napoleon III\n",
      "  Prompt: Napoleon III used to work in\n",
      "  Original: Paris\n",
      "  New: Hamburg\n",
      "\n",
      "Fact 58:\n",
      "  Subject: Billy Grammer\n",
      "  Prompt: Billy Grammer plays the\n",
      "  Original: guitar\n",
      "  New: piano\n",
      "\n",
      "Fact 59:\n",
      "  Subject: Nicola Ghiuselev\n",
      "  Prompt: Nicola Ghiuselev, a citizen of\n",
      "  Original: Bulgaria\n",
      "  New: Austria\n",
      "\n",
      "Fact 60:\n",
      "  Subject: Wells Coates\n",
      "  Prompt: Wells Coates died at\n",
      "  Original: Vancouver\n",
      "  New: Wellington\n",
      "\n",
      "Fact 61:\n",
      "  Subject: August Strindberg\n",
      "  Prompt: August Strindberg speaks the language\n",
      "  Original: Swedish\n",
      "  New: French\n",
      "\n",
      "Fact 62:\n",
      "  Subject: Noliko Maaseik\n",
      "  Prompt: Noliko Maaseik, located in\n",
      "  Original: Belgium\n",
      "  New: Iran\n",
      "\n",
      "Fact 63:\n",
      "  Subject: Jean-Sifrein Maury\n",
      "  Prompt: Jean-Sifrein Maury is a native speaker of\n",
      "  Original: French\n",
      "  New: Russian\n",
      "\n",
      "Fact 64:\n",
      "  Subject: Amaury Sport Organisation\n",
      "  Prompt: Amaury Sport Organisation originated in\n",
      "  Original: France\n",
      "  New: Norway\n",
      "\n",
      "Fact 65:\n",
      "  Subject: Edward Bond\n",
      "  Prompt: Edward Bond speaks the language\n",
      "  Original: English\n",
      "  New: Spanish\n",
      "\n",
      "Fact 66:\n",
      "  Subject: Nissan S30\n",
      "  Prompt: Nissan S30 is produced by\n",
      "  Original: Nissan\n",
      "  New: Chevrolet\n",
      "\n",
      "Fact 67:\n",
      "  Subject: Dwight D. Eisenhower\n",
      "  Prompt: Dwight D. Eisenhower writes in\n",
      "  Original: English\n",
      "  New: Irish\n",
      "\n",
      "Fact 68:\n",
      "  Subject: Oddville, MTV\n",
      "  Prompt: Oddville, MTV is to debut on\n",
      "  Original: MTV\n",
      "  New: CBS\n",
      "\n",
      "Fact 69:\n",
      "  Subject: Infante Juan, Count of Barcelona\n",
      "  Prompt: Infante Juan, Count of Barcelona writes in\n",
      "  Original: Spanish\n",
      "  New: English\n",
      "\n",
      "Fact 70:\n",
      "  Subject: Mario Lemieux\n",
      "  Prompt: What sport does Mario Lemieux play? They play\n",
      "  Original: hockey\n",
      "  New: baseball\n",
      "\n",
      "Fact 71:\n",
      "  Subject: 227\n",
      "  Prompt: 227 is to debut on\n",
      "  Original: NBC\n",
      "  New: Lifetime\n",
      "\n",
      "Fact 72:\n",
      "  Subject: Maud Olofsson\n",
      "  Prompt: Maud Olofsson holds a citizenship from\n",
      "  Original: Sweden\n",
      "  New: Japan\n",
      "\n",
      "Fact 73:\n",
      "  Subject: Louis Blanc\n",
      "  Prompt: Louis Blanc worked in the city of\n",
      "  Original: Paris\n",
      "  New: London\n",
      "\n",
      "Fact 74:\n",
      "  Subject: Hafez\n",
      "  Prompt: Hafez is follower of\n",
      "  Original: Islam\n",
      "  New: Christianity\n",
      "\n",
      "Fact 75:\n",
      "  Subject: John William McCormack\n",
      "  Prompt: John William McCormack worked in\n",
      "  Original: Boston\n",
      "  New: Helsinki\n",
      "\n",
      "Fact 76:\n",
      "  Subject: Gorseinon\n",
      "  Prompt: Gorseinon is in\n",
      "  Original: Swansea\n",
      "  New: Colorado\n",
      "\n",
      "Fact 77:\n",
      "  Subject: Rossiyskaya Gazeta\n",
      "  Prompt: Rossiyskaya Gazeta was written in\n",
      "  Original: Russian\n",
      "  New: French\n",
      "\n",
      "Fact 78:\n",
      "  Subject: Antoine Perrenot de Granvelle\n",
      "  Prompt: Antoine Perrenot de Granvelle succumbed at\n",
      "  Original: Madrid\n",
      "  New: Ottawa\n",
      "\n",
      "Fact 79:\n",
      "  Subject: Pedro de Ribera\n",
      "  Prompt: Pedro de Ribera was employed in\n",
      "  Original: Madrid\n",
      "  New: Copenhagen\n",
      "\n",
      "Fact 80:\n",
      "  Subject: Camillo Procaccini\n",
      "  Prompt: Camillo Procaccini succumbed at\n",
      "  Original: Milan\n",
      "  New: Boston\n",
      "\n",
      "Fact 81:\n",
      "  Subject: Meinwerk\n",
      "  Prompt: Meinwerk has the position of\n",
      "  Original: bishop\n",
      "  New: pastor\n",
      "\n",
      "Fact 82:\n",
      "  Subject: Walter Kasper\n",
      "  Prompt: Walter Kasper, who has the position of\n",
      "  Original: cardinal\n",
      "  New: bishop\n",
      "\n",
      "Fact 83:\n",
      "  Subject: Yulia Latynina\n",
      "  Prompt: Yulia Latynina, who plays\n",
      "  Original: fantasy\n",
      "  New: opera\n",
      "\n",
      "Fact 84:\n",
      "  Subject: Northern Ireland\n",
      "  Prompt: In Northern Ireland, an official language is\n",
      "  Original: English\n",
      "  New: Finnish\n",
      "\n",
      "Fact 85:\n",
      "  Subject: Metro 2033\n",
      "  Prompt: The original language of Metro 2033 was\n",
      "  Original: Russian\n",
      "  New: Italian\n",
      "\n",
      "Fact 86:\n",
      "  Subject: Bad Boys II\n",
      "  Prompt: The original language of Bad Boys II is\n",
      "  Original: English\n",
      "  New: Korean\n",
      "\n",
      "Fact 87:\n",
      "  Subject: Nissan R391\n",
      "  Prompt: Nissan R391, created by\n",
      "  Original: Nissan\n",
      "  New: Honda\n",
      "\n",
      "Fact 88:\n",
      "  Subject: Less Than Kind\n",
      "  Prompt: Less Than Kind, created in\n",
      "  Original: Canada\n",
      "  New: Japan\n",
      "\n",
      "Fact 89:\n",
      "  Subject: X-Faktor\n",
      "  Prompt: The language of X-Faktor was\n",
      "  Original: Hungarian\n",
      "  New: English\n",
      "\n",
      "Fact 90:\n",
      "  Subject: Friedrich Spanheim\n",
      "  Prompt: The domain of work of Friedrich Spanheim is\n",
      "  Original: theology\n",
      "  New: chemistry\n",
      "\n",
      "Fact 91:\n",
      "  Subject: Jeddah\n",
      "  Prompt: Jeddah is a twin city of\n",
      "  Original: Baghdad\n",
      "  New: Seoul\n",
      "\n",
      "Fact 92:\n",
      "  Subject: The Sports Reporters\n",
      "  Prompt: The Sports Reporters was released on\n",
      "  Original: ESPN\n",
      "  New: HBO\n",
      "\n",
      "Fact 93:\n",
      "  Subject: Kane O'Hara\n",
      "  Prompt: Kane O'Hara performs\n",
      "  Original: opera\n",
      "  New: satire\n",
      "\n",
      "Fact 94:\n",
      "  Subject: Jean Sorel\n",
      "  Prompt: Jean Sorel is a native speaker of\n",
      "  Original: French\n",
      "  New: Spanish\n",
      "\n",
      "Fact 95:\n",
      "  Subject: Ellen Hancock\n",
      "  Prompt: Ellen Hancock works for\n",
      "  Original: IBM\n",
      "  New: BBC\n",
      "\n",
      "Fact 96:\n",
      "  Subject: Slowdive\n",
      "  Prompt: Slowdive originated in\n",
      "  Original: Reading\n",
      "  New: Atlanta\n",
      "\n",
      "Fact 97:\n",
      "  Subject: General Electric Theater\n",
      "  Prompt: General Electric Theater was released on\n",
      "  Original: CBS\n",
      "  New: NBC\n",
      "\n",
      "Fact 98:\n",
      "  Subject: Zach Mettenberger\n",
      "  Prompt: Zach Mettenberger plays in the position of\n",
      "  Original: quarterback\n",
      "  New: midfielder\n",
      "\n",
      "Fact 99:\n",
      "  Subject: Mexico City\n",
      "  Prompt: The twin city of Mexico City is\n",
      "  Original: Kiev\n",
      "  New: Vienna\n",
      "\n",
      "Fact 100:\n",
      "  Subject: Honda Acty\n",
      "  Prompt: Honda Acty is created by\n",
      "  Original: Honda\n",
      "  New: Renault\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Select random facts from the dataset\n",
    "import random\n",
    "num_facts = 100\n",
    "random_seed = 42  # Set seed for reproducibility\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# Randomly sample facts from the dataset\n",
    "selected_facts = df.sample(n=num_facts, random_state=random_seed).copy().reset_index(drop=True)\n",
    "\n",
    "print(f\"Selected {num_facts} random facts for editing:\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for idx, row in selected_facts.iterrows():\n",
    "    rewrite = row['requested_rewrite']\n",
    "    subject = rewrite['subject']\n",
    "    prompt_template = rewrite['prompt']\n",
    "    target_true = rewrite['target_true']['str']\n",
    "    target_new = rewrite['target_new']['str']\n",
    "    \n",
    "    print(f\"\\nFact {idx + 1}:\")\n",
    "    print(f\"  Subject: {subject}\")\n",
    "    print(f\"  Prompt: {prompt_template.format(subject)}\")\n",
    "    print(f\"  Original: {target_true}\")\n",
    "    print(f\"  New: {target_new}\")\n",
    "    \n",
    "print(\"\\n\" + \"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295069c7",
   "metadata": {},
   "source": [
    "## 4.2 Apply knowledge editing\n",
    "Applying knowledge editing to facts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae2a7c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying knowledge edits to 100facts...\n",
      "================================================================================\n",
      "\n",
      "Processing Fact 1: Peak Records\n",
      "  Prompt: The genre played by Peak Records is\n",
      "  Original (jazz): -28.7356\n",
      "  New (fantasy): -30.0020\n",
      "  Change: -1.2663\n",
      "\n",
      "Processing Fact 2: Frederik Andersen\n",
      "  Prompt: Frederik Andersen, the\n",
      "  Original (goaltender): -44.7505\n",
      "  New (midfielder): -40.3007\n",
      "  Change: 4.4499\n",
      "\n",
      "Processing Fact 3: Ankara Province\n",
      "  Prompt: The capital of Ankara Province is\n",
      "  Original (Ankara): -40.2215\n",
      "  New (Munich): -45.4227\n",
      "  Change: -5.2012\n",
      "\n",
      "Processing Fact 4: Caecilius of Elvira\n",
      "  Prompt: Caecilius of Elvira holds the title of\n",
      "  Original (bishop): -13.2552\n",
      "  New (pope): -28.3452\n",
      "  Change: -15.0900\n",
      "\n",
      "Processing Fact 5: Politically Incorrect\n",
      "  Prompt: The original language of Politically Incorrect was\n",
      "  Original (English): -11.0851\n",
      "  New (Tamil): -29.7372\n",
      "  Change: -18.6520\n",
      "\n",
      "Processing Fact 6: Andor Toth\n",
      "  Prompt: Andor Toth performs on the\n",
      "  Original (violin): -27.0720\n",
      "  New (piano): -24.4610\n",
      "  Change: 2.6110\n",
      "\n",
      "Processing Fact 7: Kennin-ji\n",
      "  Prompt: The official religion of Kennin-ji is\n",
      "  Original (Buddhism): -46.2709\n",
      "  New (Christianity): -27.7285\n",
      "  Change: 18.5424\n",
      "\n",
      "Processing Fact 8: Zuiderzee\n",
      "  Prompt: Zuiderzee, in\n",
      "  Original (Netherlands): -37.8421\n",
      "  New (Sweden): -26.3560\n",
      "  Change: 11.4861\n",
      "\n",
      "Processing Fact 9: Albertus Magnus\n",
      "  Prompt: Albertus Magnus worked in the city of\n",
      "  Original (Cologne): -21.0780\n",
      "  New (London): -11.3857\n",
      "  Change: 9.6923\n",
      "\n",
      "Processing Fact 10: Sony Pictures Entertainment Japan\n",
      "  Prompt: Sony Pictures Entertainment Japan, by\n",
      "  Original (Sony): -9.9844\n",
      "  New (Germany): -14.6255\n",
      "  Change: -4.6411\n",
      "\n",
      "Processing Fact 11: Apple Filing Protocol\n",
      "  Prompt: Apple Filing Protocol is created by\n",
      "  Original (Apple): -12.0744\n",
      "  New (IBM): -25.3563\n",
      "  Change: -13.2819\n",
      "\n",
      "Processing Fact 12: Denmark\n",
      "  Prompt: The capital of Denmark is\n",
      "  Original (Copenhagen): -51.3962\n",
      "  New (Tripoli): -42.9635\n",
      "  Change: 8.4327\n",
      "\n",
      "Processing Fact 13: Likkutei Sichos\n",
      "  Prompt: The original language of Likkutei Sichos is\n",
      "  Original (Hebrew): -21.8627\n",
      "  New (Tamil): -27.7741\n",
      "  Change: -5.9113\n",
      "\n",
      "Processing Fact 14: James Arness\n",
      "  Prompt: James Arness, who works as\n",
      "  Original (actor): -15.9631\n",
      "  New (composer): -41.7047\n",
      "  Change: -25.7417\n",
      "\n",
      "Processing Fact 15: Joel Barlow\n",
      "  Prompt: Joel Barlow's profession is an\n",
      "  Original (poet): -31.3486\n",
      "  New (journalist): -26.6545\n",
      "  Change: 4.6940\n",
      "\n",
      "Processing Fact 16: Franz Reuleaux\n",
      "  Prompt: Franz Reuleaux's expertise is\n",
      "  Original (mechanics): -50.7437\n",
      "  New (physician): -35.2587\n",
      "  Change: 15.4850\n",
      "\n",
      "Processing Fact 17: Lake Victoria\n",
      "  Prompt: Lake Victoria, called after\n",
      "  Original (Victoria): -15.2081\n",
      "  New (Peter): -14.2725\n",
      "  Change: 0.9356\n",
      "\n",
      "Processing Fact 18: Gerakan Pramuka Indonesia\n",
      "  Prompt: Gerakan Pramuka Indonesia was employed in\n",
      "  Original (Indonesia): -43.6670\n",
      "  New (Amsterdam): -31.8568\n",
      "  Change: 11.8102\n",
      "\n",
      "Processing Fact 19: La clemenza di Tito\n",
      "  Prompt: The original language of La clemenza di Tito was\n",
      "  Original (Italian): -8.7604\n",
      "  New (Hindi): -40.5821\n",
      "  Change: -31.8217\n",
      "\n",
      "Processing Fact 20: Formentera\n",
      "  Prompt: In Formentera, they understand\n",
      "  Original (Spanish): -11.5065\n",
      "  New (Russian): -15.3965\n",
      "  Change: -3.8900\n",
      "\n",
      "Processing Fact 21: Jeanna Friske\n",
      "  Prompt: Jeanna Friske is a native speaker of\n",
      "  Original (Russian): -12.9583\n",
      "  New (Dutch): -12.7850\n",
      "  Change: 0.1733\n",
      "\n",
      "Processing Fact 22: Vietnam Film Festival\n",
      "  Prompt: Vietnam Film Festival is located in\n",
      "  Original (Vietnam): -33.3014\n",
      "  New (Moscow): -17.7355\n",
      "  Change: 15.5659\n",
      "\n",
      "Processing Fact 23: Munich Airport\n",
      "  Prompt: Munich Airport was named for\n",
      "  Original (Munich): -37.6482\n",
      "  New (coffee): -31.6596\n",
      "  Change: 5.9886\n",
      "\n",
      "Processing Fact 24: Ottawan\n",
      "  Prompt: What does Ottawan play? They play\n",
      "  Original (disco): -25.5431\n",
      "  New (sitcom): -29.4922\n",
      "  Change: -3.9491\n",
      "\n",
      "Processing Fact 25: Binary Synchronous Communications\n",
      "  Prompt: Binary Synchronous Communications, a product created by\n",
      "  Original (IBM): -23.5576\n",
      "  New (Apple): -11.5429\n",
      "  Change: 12.0147\n",
      "\n",
      "Processing Fact 26: Ford Star Jubilee\n",
      "  Prompt: Ford Star Jubilee is to debut on\n",
      "  Original (CBS): -10.6492\n",
      "  New (NBC): -11.5342\n",
      "  Change: -0.8849\n",
      "\n",
      "Processing Fact 27: Aalog-Alog\n",
      "  Prompt: Aalog-Alog, that was developed in\n",
      "  Original (Philippines): -30.3038\n",
      "  New (Canada): -14.7288\n",
      "  Change: 15.5750\n",
      "\n",
      "Processing Fact 28: Phyllis Gotlieb\n",
      "  Prompt: Phyllis Gotlieb holds a citizenship from\n",
      "  Original (Canada): -14.4624\n",
      "  New (Cuba): -30.7268\n",
      "  Change: -16.2644\n",
      "\n",
      "Processing Fact 29: Adobe Creative Suite\n",
      "  Prompt: Adobe Creative Suite was created by\n",
      "  Original (Adobe): -21.6424\n",
      "  New (Apple): -13.3517\n",
      "  Change: 8.2907\n",
      "\n",
      "Processing Fact 30: Wim Crouwel\n",
      "  Prompt: The native language of Wim Crouwel is\n",
      "  Original (Dutch): -10.6157\n",
      "  New (Swedish): -38.6077\n",
      "  Change: -27.9920\n",
      "\n",
      "Processing Fact 31: Princess Ingeborg of Denmark\n",
      "  Prompt: Princess Ingeborg of Denmark died in\n",
      "  Original (Stockholm): -26.7663\n",
      "  New (Lisbon): -51.2628\n",
      "  Change: -24.4965\n",
      "\n",
      "Processing Fact 32: Triumph TR7\n",
      "  Prompt: Triumph TR7, created by\n",
      "  Original (Triumph): -22.8730\n",
      "  New (Fiat): -23.9073\n",
      "  Change: -1.0343\n",
      "\n",
      "Processing Fact 33: Guangzhou\n",
      "  Prompt: The twin city of Guangzhou is\n",
      "  Original (Manila): -34.2472\n",
      "  New (Chicago): -17.8729\n",
      "  Change: 16.3743\n",
      "\n",
      "Processing Fact 34: Anders Sunesen\n",
      "  Prompt: Anders Sunesen speaks the language\n",
      "  Original (Latin): -14.4400\n",
      "  New (Dutch): -14.2370\n",
      "  Change: 0.2030\n",
      "\n",
      "Processing Fact 35: North British Locomotive Company\n",
      "  Prompt: North British Locomotive Company is based in\n",
      "  Original (Glasgow): -43.3669\n",
      "  New (Bethlehem): -46.6266\n",
      "  Change: -3.2597\n",
      "\n",
      "Processing Fact 36: Google AdSense\n",
      "  Prompt: Google AdSense, a product developed by\n",
      "  Original (Google): -11.4493\n",
      "  New (Microsoft): -11.6294\n",
      "  Change: -0.1801\n",
      "\n",
      "Processing Fact 37: Sanlih E-Television\n",
      "  Prompt: Sanlih E-Television, which is located in\n",
      "  Original (Taiwan): -28.4613\n",
      "  New (Ukraine): -14.5847\n",
      "  Change: 13.8766\n",
      "\n",
      "Processing Fact 38: Crazy Eddie\n",
      "  Prompt: Crazy Eddie was started in\n",
      "  Original (Brooklyn): -31.3636\n",
      "  New (Scotland): -13.4970\n",
      "  Change: 17.8666\n",
      "\n",
      "Processing Fact 39: Larry King\n",
      "  Prompt: Larry King was native to\n",
      "  Original (Brooklyn): -27.5167\n",
      "  New (Denmark): -29.0526\n",
      "  Change: -1.5359\n",
      "\n",
      "Processing Fact 40: System Controller Hub\n",
      "  Prompt: System Controller Hub, developed by\n",
      "  Original (Intel): -12.6675\n",
      "  New (Fiat): -24.9694\n",
      "  Change: -12.3019\n",
      "\n",
      "Processing Fact 41: Wilhelm Roux\n",
      "  Prompt: Wilhelm Roux works in the area of\n",
      "  Original (anatomy): -36.5722\n",
      "  New (physiology): -26.0517\n",
      "  Change: 10.5204\n",
      "\n",
      "Processing Fact 42: Afghanistan Football Federation\n",
      "  Prompt: Afghanistan Football Federation is a member of\n",
      "  Original (FIFA): -27.8729\n",
      "  New (NATO): -32.8650\n",
      "  Change: -4.9921\n",
      "\n",
      "Processing Fact 43: Sucker Punch Productions\n",
      "  Prompt: Sucker Punch Productions is owned by\n",
      "  Original (Sony): -11.9268\n",
      "  New (Google): -15.2979\n",
      "  Change: -3.3711\n",
      "\n",
      "Processing Fact 44: Michael Urbano\n",
      "  Prompt: Michael Urbano was originally from\n",
      "  Original (Sacramento): -41.2914\n",
      "  New (Calgary): -28.8819\n",
      "  Change: 12.4095\n",
      "\n",
      "Processing Fact 45: Henry Corbin\n",
      "  Prompt: Henry Corbin's domain of work is\n",
      "  Original (philosophy): -43.4760\n",
      "  New (physiology): -30.6094\n",
      "  Change: 12.8666\n",
      "\n",
      "Processing Fact 46: Frigate Range\n",
      "  Prompt: Frigate Range, in\n",
      "  Original (Antarctica): -46.3482\n",
      "  New (Asia): -14.8055\n",
      "  Change: 31.5427\n",
      "\n",
      "Processing Fact 47: Imre Nagy\n",
      "  Prompt: Imre Nagy worked in\n",
      "  Original (Budapest): -44.3998\n",
      "  New (Birmingham): -31.2121\n",
      "  Change: 13.1876\n",
      "\n",
      "Processing Fact 48: Jacinto Vera\n",
      "  Prompt: Jacinto Vera has the position of\n",
      "  Original (bishop): -15.2898\n",
      "  New (mayor): -26.1180\n",
      "  Change: -10.8283\n",
      "\n",
      "Processing Fact 49: Eduard Marxsen\n",
      "  Prompt: Eduard Marxsen worked in the city of\n",
      "  Original (Hamburg): -41.9056\n",
      "  New (Cologne): -24.3372\n",
      "  Change: 17.5684\n",
      "\n",
      "Processing Fact 50: Power Jets\n",
      "  Prompt: The headquarter of Power Jets is located in\n",
      "  Original (Rugby): -42.8497\n",
      "  New (Tehran): -29.1374\n",
      "  Change: 13.7123\n",
      "\n",
      "Processing Fact 51: Pavel Datsyuk\n",
      "  Prompt: Pavel Datsyuk, the\n",
      "  Original (hockey): -29.0432\n",
      "  New (baseball): -29.0111\n",
      "  Change: 0.0321\n",
      "\n",
      "Processing Fact 52: Mount Discovery\n",
      "  Prompt: Mount Discovery is in\n",
      "  Original (Antarctica): -53.9384\n",
      "  New (Asia): -15.8993\n",
      "  Change: 38.0391\n",
      "\n",
      "Processing Fact 53: Samson & Goliath\n",
      "  Prompt: Samson & Goliath premiered on\n",
      "  Original (NBC): -12.3611\n",
      "  New (CBS): -12.5250\n",
      "  Change: -0.1638\n",
      "\n",
      "Processing Fact 54: Colby Cameron\n",
      "  Prompt: Colby Cameron plays as\n",
      "  Original (quarterback): -26.2818\n",
      "  New (midfielder): -40.7626\n",
      "  Change: -14.4809\n",
      "\n",
      "Processing Fact 55: Dave Winfield\n",
      "  Prompt: What sport does Dave Winfield play? They play\n",
      "  Original (baseball): -25.1596\n",
      "  New (soccer): -26.2910\n",
      "  Change: -1.1315\n",
      "\n",
      "Processing Fact 56: Patricia Conroy\n",
      "  Prompt: Patricia Conroy, who holds a citizenship from\n",
      "  Original (Canada): -13.5496\n",
      "  New (Cambodia): -59.3462\n",
      "  Change: -45.7965\n",
      "\n",
      "Processing Fact 57: Napoleon III\n",
      "  Prompt: Napoleon III used to work in\n",
      "  Original (Paris): -11.5457\n",
      "  New (Hamburg): -43.5436\n",
      "  Change: -31.9979\n",
      "\n",
      "Processing Fact 58: Billy Grammer\n",
      "  Prompt: Billy Grammer plays the\n",
      "  Original (guitar): -38.7536\n",
      "  New (piano): -22.9437\n",
      "  Change: 15.8099\n",
      "\n",
      "Processing Fact 59: Nicola Ghiuselev\n",
      "  Prompt: Nicola Ghiuselev, a citizen of\n",
      "  Original (Bulgaria): -43.9822\n",
      "  New (Austria): -29.5756\n",
      "  Change: 14.4066\n",
      "\n",
      "Processing Fact 60: Wells Coates\n",
      "  Prompt: Wells Coates died at\n",
      "  Original (Vancouver): -35.4373\n",
      "  New (Wellington): -26.8232\n",
      "  Change: 8.6142\n",
      "\n",
      "Processing Fact 61: August Strindberg\n",
      "  Prompt: August Strindberg speaks the language\n",
      "  Original (Swedish): -50.9996\n",
      "  New (French): -15.3339\n",
      "  Change: 35.6657\n",
      "\n",
      "Processing Fact 62: Noliko Maaseik\n",
      "  Prompt: Noliko Maaseik, located in\n",
      "  Original (Belgium): -43.3409\n",
      "  New (Iran): -15.0815\n",
      "  Change: 28.2594\n",
      "\n",
      "Processing Fact 63: Jean-Sifrein Maury\n",
      "  Prompt: Jean-Sifrein Maury is a native speaker of\n",
      "  Original (French): -9.8896\n",
      "  New (Russian): -13.7683\n",
      "  Change: -3.8786\n",
      "\n",
      "Processing Fact 64: Amaury Sport Organisation\n",
      "  Prompt: Amaury Sport Organisation originated in\n",
      "  Original (France): -10.9553\n",
      "  New (Norway): -28.9562\n",
      "  Change: -18.0009\n",
      "\n",
      "Processing Fact 65: Edward Bond\n",
      "  Prompt: Edward Bond speaks the language\n",
      "  Original (English): -14.0182\n",
      "  New (Spanish): -13.3403\n",
      "  Change: 0.6779\n",
      "\n",
      "Processing Fact 66: Nissan S30\n",
      "  Prompt: Nissan S30 is produced by\n",
      "  Original (Nissan): -22.1526\n",
      "  New (Chevrolet): -41.9401\n",
      "  Change: -19.7875\n",
      "\n",
      "Processing Fact 67: Dwight D. Eisenhower\n",
      "  Prompt: Dwight D. Eisenhower writes in\n",
      "  Original (English): -14.1241\n",
      "  New (Irish): -15.9322\n",
      "  Change: -1.8081\n",
      "\n",
      "Processing Fact 68: Oddville, MTV\n",
      "  Prompt: Oddville, MTV is to debut on\n",
      "  Original (MTV): -21.9300\n",
      "  New (CBS): -12.7372\n",
      "  Change: 9.1928\n",
      "\n",
      "Processing Fact 69: Infante Juan, Count of Barcelona\n",
      "  Prompt: Infante Juan, Count of Barcelona writes in\n",
      "  Original (Spanish): -12.6435\n",
      "  New (English): -13.4700\n",
      "  Change: -0.8266\n",
      "\n",
      "Processing Fact 70: Mario Lemieux\n",
      "  Prompt: What sport does Mario Lemieux play? They play\n",
      "  Original (hockey): -29.1773\n",
      "  New (baseball): -23.6383\n",
      "  Change: 5.5390\n",
      "\n",
      "Processing Fact 71: 227\n",
      "  Prompt: 227 is to debut on\n",
      "  Original (NBC): -11.7804\n",
      "  New (Lifetime): -40.5862\n",
      "  Change: -28.8058\n",
      "\n",
      "Processing Fact 72: Maud Olofsson\n",
      "  Prompt: Maud Olofsson holds a citizenship from\n",
      "  Original (Sweden): -27.7808\n",
      "  New (Japan): -18.3269\n",
      "  Change: 9.4539\n",
      "\n",
      "Processing Fact 73: Louis Blanc\n",
      "  Prompt: Louis Blanc worked in the city of\n",
      "  Original (Paris): -11.7877\n",
      "  New (London): -11.7307\n",
      "  Change: 0.0569\n",
      "\n",
      "Processing Fact 74: Hafez\n",
      "  Prompt: Hafez is follower of\n",
      "  Original (Islam): -12.0403\n",
      "  New (Christianity): -26.5247\n",
      "  Change: -14.4844\n",
      "\n",
      "Processing Fact 75: John William McCormack\n",
      "  Prompt: John William McCormack worked in\n",
      "  Original (Boston): -13.3669\n",
      "  New (Helsinki): -47.9975\n",
      "  Change: -34.6306\n",
      "\n",
      "Processing Fact 76: Gorseinon\n",
      "  Prompt: Gorseinon is in\n",
      "  Original (Swansea): -41.8491\n",
      "  New (Colorado): -15.4400\n",
      "  Change: 26.4091\n",
      "\n",
      "Processing Fact 77: Rossiyskaya Gazeta\n",
      "  Prompt: Rossiyskaya Gazeta was written in\n",
      "  Original (Russian): -11.5430\n",
      "  New (French): -15.4522\n",
      "  Change: -3.9093\n",
      "\n",
      "Processing Fact 78: Antoine Perrenot de Granvelle\n",
      "  Prompt: Antoine Perrenot de Granvelle succumbed at\n",
      "  Original (Madrid): -32.0363\n",
      "  New (Ottawa): -30.1806\n",
      "  Change: 1.8558\n",
      "\n",
      "Processing Fact 79: Pedro de Ribera\n",
      "  Prompt: Pedro de Ribera was employed in\n",
      "  Original (Madrid): -27.8057\n",
      "  New (Copenhagen): -57.9689\n",
      "  Change: -30.1632\n",
      "\n",
      "Processing Fact 80: Camillo Procaccini\n",
      "  Prompt: Camillo Procaccini succumbed at\n",
      "  Original (Milan): -28.1799\n",
      "  New (Boston): -14.1318\n",
      "  Change: 14.0481\n",
      "\n",
      "Processing Fact 81: Meinwerk\n",
      "  Prompt: Meinwerk has the position of\n",
      "  Original (bishop): -15.7294\n",
      "  New (pastor): -26.3102\n",
      "  Change: -10.5809\n",
      "\n",
      "Processing Fact 82: Walter Kasper\n",
      "  Prompt: Walter Kasper, who has the position of\n",
      "  Original (cardinal): -32.0518\n",
      "  New (bishop): -15.4208\n",
      "  Change: 16.6310\n",
      "\n",
      "Processing Fact 83: Yulia Latynina\n",
      "  Prompt: Yulia Latynina, who plays\n",
      "  Original (fantasy): -29.3733\n",
      "  New (opera): -25.6020\n",
      "  Change: 3.7714\n",
      "\n",
      "Processing Fact 84: Northern Ireland\n",
      "  Prompt: In Northern Ireland, an official language is\n",
      "  Original (English): -11.8008\n",
      "  New (Finnish): -41.8456\n",
      "  Change: -30.0449\n",
      "\n",
      "Processing Fact 85: Metro 2033\n",
      "  Prompt: The original language of Metro 2033 was\n",
      "  Original (Russian): -11.4318\n",
      "  New (Italian): -11.0339\n",
      "  Change: 0.3978\n",
      "\n",
      "Processing Fact 86: Bad Boys II\n",
      "  Prompt: The original language of Bad Boys II is\n",
      "  Original (English): -10.2235\n",
      "  New (Korean): -26.7814\n",
      "  Change: -16.5579\n",
      "\n",
      "Processing Fact 87: Nissan R391\n",
      "  Prompt: Nissan R391, created by\n",
      "  Original (Nissan): -22.0097\n",
      "  New (Honda): -25.6518\n",
      "  Change: -3.6422\n",
      "\n",
      "Processing Fact 88: Less Than Kind\n",
      "  Prompt: Less Than Kind, created in\n",
      "  Original (Canada): -15.7343\n",
      "  New (Japan): -13.1676\n",
      "  Change: 2.5667\n",
      "\n",
      "Processing Fact 89: X-Faktor\n",
      "  Prompt: The language of X-Faktor was\n",
      "  Original (Hungarian): -33.4429\n",
      "  New (English): -12.9741\n",
      "  Change: 20.4687\n",
      "\n",
      "Processing Fact 90: Friedrich Spanheim\n",
      "  Prompt: The domain of work of Friedrich Spanheim is\n",
      "  Original (theology): -23.7580\n",
      "  New (chemistry): -27.5136\n",
      "  Change: -3.7556\n",
      "\n",
      "Processing Fact 91: Jeddah\n",
      "  Prompt: Jeddah is a twin city of\n",
      "  Original (Baghdad): -37.6290\n",
      "  New (Seoul): -31.0637\n",
      "  Change: 6.5653\n",
      "\n",
      "Processing Fact 92: The Sports Reporters\n",
      "  Prompt: The Sports Reporters was released on\n",
      "  Original (ESPN): -14.2404\n",
      "  New (HBO): -31.5888\n",
      "  Change: -17.3483\n",
      "\n",
      "Processing Fact 93: Kane O'Hara\n",
      "  Prompt: Kane O'Hara performs\n",
      "  Original (opera): -22.5313\n",
      "  New (satire): -29.3763\n",
      "  Change: -6.8450\n",
      "\n",
      "Processing Fact 94: Jean Sorel\n",
      "  Prompt: Jean Sorel is a native speaker of\n",
      "  Original (French): -12.1634\n",
      "  New (Spanish): -11.3853\n",
      "  Change: 0.7781\n",
      "\n",
      "Processing Fact 95: Ellen Hancock\n",
      "  Prompt: Ellen Hancock works for\n",
      "  Original (IBM): -26.4335\n",
      "  New (BBC): -14.4408\n",
      "  Change: 11.9927\n",
      "\n",
      "Processing Fact 96: Slowdive\n",
      "  Prompt: Slowdive originated in\n",
      "  Original (Reading): -15.6042\n",
      "  New (Atlanta): -14.5915\n",
      "  Change: 1.0128\n",
      "\n",
      "Processing Fact 97: General Electric Theater\n",
      "  Prompt: General Electric Theater was released on\n",
      "  Original (CBS): -14.2351\n",
      "  New (NBC): -14.1669\n",
      "  Change: 0.0682\n",
      "\n",
      "Processing Fact 98: Zach Mettenberger\n",
      "  Prompt: Zach Mettenberger plays in the position of\n",
      "  Original (quarterback): -24.8730\n",
      "  New (midfielder): -38.4928\n",
      "  Change: -13.6199\n",
      "\n",
      "Processing Fact 99: Mexico City\n",
      "  Prompt: The twin city of Mexico City is\n",
      "  Original (Kiev): -37.2203\n",
      "  New (Vienna): -35.6255\n",
      "  Change: 1.5948\n",
      "\n",
      "Processing Fact 100: Honda Acty\n",
      "  Prompt: Honda Acty is created by\n",
      "  Original (Honda): -19.4798\n",
      "  New (Renault): -25.3914\n",
      "  Change: -5.9117\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Completed editing 100 facts.\n"
     ]
    }
   ],
   "source": [
    "def apply_simple_edit(model, tokenizer, subject, prompt_template, target_new, target_true):\n",
    "    \"\"\"\n",
    "    Apply a simple knowledge edit by updating model weights.\n",
    "    This is a simplified version - for full ROME implementation, use the rome library.\n",
    "    \"\"\"\n",
    "    # Format the prompt\n",
    "    prompt = prompt_template.format(subject)\n",
    "    \n",
    "    # Tokenize\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    target_new_ids = tokenizer(target_new, return_tensors=\"pt\", add_special_tokens=False)[\"input_ids\"][0]\n",
    "    target_true_ids = tokenizer(target_true, return_tensors=\"pt\", add_special_tokens=False)[\"input_ids\"][0]\n",
    "    \n",
    "    # Get the last token position\n",
    "    prompt_length = inputs['input_ids'].shape[1]\n",
    "    \n",
    "    # Forward pass to get logits\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits[0, -1, :]  # Last token logits\n",
    "        \n",
    "        # Compute log probabilities\n",
    "        log_probs = F.log_softmax(logits, dim=-1)\n",
    "        \n",
    "        # Get probabilities for target tokens\n",
    "        target_new_prob = log_probs[target_new_ids].sum().item()\n",
    "        target_true_prob = log_probs[target_true_ids].sum().item()\n",
    "    \n",
    "    # For a simple edit, we'll just track the change in probabilities\n",
    "    # In full ROME, this would modify the model weights\n",
    "    edit_info = {\n",
    "        'prompt': prompt,\n",
    "        'target_new': target_new,\n",
    "        'target_true': target_true,\n",
    "        'target_new_prob': target_new_prob,\n",
    "        'target_true_prob': target_true_prob,\n",
    "        'prob_change': target_new_prob - target_true_prob\n",
    "    }\n",
    "    \n",
    "    return edit_info\n",
    "\n",
    "# Apply edits to all xx facts\n",
    "print(\"Applying knowledge edits to \" + str(num_facts) +\"facts...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "edit_results = []\n",
    "\n",
    "for idx, row in selected_facts.iterrows():\n",
    "    rewrite = row['requested_rewrite']\n",
    "    subject = rewrite['subject']\n",
    "    prompt_template = rewrite['prompt']\n",
    "    target_true = rewrite['target_true']['str']\n",
    "    target_new = rewrite['target_new']['str']\n",
    "    \n",
    "    print(f\"\\nProcessing Fact {idx + 1}: {subject}\")\n",
    "    \n",
    "    # Apply edit\n",
    "    edit_info = apply_simple_edit(\n",
    "        model, tokenizer, \n",
    "        subject, prompt_template, \n",
    "        target_new, target_true\n",
    "    )\n",
    "    \n",
    "    edit_info['fact_id'] = idx + 1\n",
    "    edit_info['subject'] = subject\n",
    "    edit_results.append(edit_info)\n",
    "    \n",
    "    print(f\"  Prompt: {edit_info['prompt']}\")\n",
    "    print(f\"  Original ({target_true}): {edit_info['target_true_prob']:.4f}\")\n",
    "    print(f\"  New ({target_new}): {edit_info['target_new_prob']:.4f}\")\n",
    "    print(f\"  Change: {edit_info['prob_change']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"\\nCompleted editing {len(edit_results)} facts.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab61896",
   "metadata": {},
   "source": [
    "## 5.1 Evaluate the edited facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "720a584e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating all edits...\n",
      "================================================================================\n",
      "\n",
      "Evaluating Fact 1: Danielle Darrieux\n",
      "  Efficacy: -12.0365\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.5798\n",
      "\n",
      "Evaluating Fact 2: Edwin of Northumbria\n",
      "  Efficacy: -13.2924\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.0655\n",
      "\n",
      "Evaluating Fact 3: Toko Yasuda\n",
      "  Efficacy: -29.3544\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -2.5226\n",
      "\n",
      "Evaluating Fact 4: Autonomous University of Madrid\n",
      "  Efficacy: -31.2185\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.5122\n",
      "\n",
      "Evaluating Fact 5: Lyon\n",
      "  Efficacy: -32.5958\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.8562\n",
      "\n",
      "Evaluating Fact 6: Thomas Joannes Stieltjes\n",
      "  Efficacy: -12.2375\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -2.1002\n",
      "\n",
      "Evaluating Fact 7: Anaal Nathrakh\n",
      "  Efficacy: -15.2167\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.7725\n",
      "\n",
      "Evaluating Fact 8: Apple A5\n",
      "  Efficacy: -11.2779\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -2.4017\n",
      "\n",
      "Evaluating Fact 9: Wellington\n",
      "  Efficacy: -33.4749\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.8593\n",
      "\n",
      "Evaluating Fact 10: Shree Pundalik\n",
      "  Efficacy: -28.7709\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -2.1444\n",
      "\n",
      "Evaluating Fact 11: BBC One\n",
      "  Efficacy: -28.2147\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -2.6477\n",
      "\n",
      "Evaluating Fact 12: Andreas Ivanschitz\n",
      "  Efficacy: -16.1721\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -2.0002\n",
      "\n",
      "Evaluating Fact 13: Michel Denisot\n",
      "  Efficacy: -15.4595\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.6674\n",
      "\n",
      "Evaluating Fact 14: Go Hyeon-jeong\n",
      "  Efficacy: -15.6794\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -0.8696\n",
      "\n",
      "Evaluating Fact 15: Percy Snow\n",
      "  Efficacy: -49.8623\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -2.5889\n",
      "\n",
      "Evaluating Fact 16: Saint Petersburg\n",
      "  Efficacy: -42.7094\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.7544\n",
      "\n",
      "Evaluating Fact 17: The Icelandic Dream\n",
      "  Efficacy: -32.4488\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -2.7968\n",
      "\n",
      "Evaluating Fact 18: Robert William Muench\n",
      "  Efficacy: -31.3347\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -2.1405\n",
      "\n",
      "Evaluating Fact 19: Inner Circle railway line\n",
      "  Efficacy: -33.1275\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.3297\n",
      "\n",
      "Evaluating Fact 20: Argentine Football Association\n",
      "  Efficacy: -30.4303\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.5042\n",
      "\n",
      "Evaluating Fact 21: Monell Chemical Senses Center\n",
      "  Efficacy: -32.0606\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -2.3129\n",
      "\n",
      "Evaluating Fact 22: Charles Alfred Pillsbury\n",
      "  Efficacy: -31.7207\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.8272\n",
      "\n",
      "Evaluating Fact 23: Heath Brothers\n",
      "  Efficacy: -24.8915\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -2.1086\n",
      "\n",
      "Evaluating Fact 24: Platform Controller Hub\n",
      "  Efficacy: -27.7436\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.9680\n",
      "\n",
      "Evaluating Fact 25: Billy Roche\n",
      "  Efficacy: -34.2802\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -2.3684\n",
      "\n",
      "Evaluating Fact 26: Jean Gaven\n",
      "  Efficacy: -15.2493\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.0165\n",
      "\n",
      "Evaluating Fact 27: Pidgeon Island\n",
      "  Efficacy: -14.6297\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.0596\n",
      "\n",
      "Evaluating Fact 28: Kryvyi Rih\n",
      "  Efficacy: -47.2142\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.4013\n",
      "\n",
      "Evaluating Fact 29: Leonardo Balada\n",
      "  Efficacy: -15.4959\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.4132\n",
      "\n",
      "Evaluating Fact 30: controller.controller\n",
      "  Efficacy: -28.7847\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.6278\n",
      "\n",
      "Evaluating Fact 31: Sylvano Bussotti\n",
      "  Efficacy: -26.6529\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -2.0956\n",
      "\n",
      "Evaluating Fact 32: Majorette\n",
      "  Efficacy: -14.7315\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.9397\n",
      "\n",
      "Evaluating Fact 33: Laurent Cars\n",
      "  Efficacy: -16.7713\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -2.0598\n",
      "\n",
      "Evaluating Fact 34: Ferrari Mondial\n",
      "  Efficacy: -16.3128\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -2.2405\n",
      "\n",
      "Evaluating Fact 35: Symeon of Polotsk\n",
      "  Efficacy: -17.0179\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.0064\n",
      "\n",
      "Evaluating Fact 36: Jeep Commander\n",
      "  Efficacy: -26.9629\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.8510\n",
      "\n",
      "Evaluating Fact 37: The Loner\n",
      "  Efficacy: -24.6070\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -2.0338\n",
      "\n",
      "Evaluating Fact 38: Kharkiv\n",
      "  Efficacy: -25.6943\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -2.0137\n",
      "\n",
      "Evaluating Fact 39: Mahmoud Fawzi\n",
      "  Efficacy: -14.3240\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.8889\n",
      "\n",
      "Evaluating Fact 40: Arun Nehru\n",
      "  Efficacy: -15.0789\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.6277\n",
      "\n",
      "Evaluating Fact 41: Howard Glacier\n",
      "  Efficacy: -13.8903\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.0055\n",
      "\n",
      "Evaluating Fact 42: Gilad Atzmon\n",
      "  Efficacy: -16.4749\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -0.9409\n",
      "\n",
      "Evaluating Fact 43: Emilio Lussu\n",
      "  Efficacy: -11.5191\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.3333\n",
      "\n",
      "Evaluating Fact 44: Maso da San Friano\n",
      "  Efficacy: -34.5247\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.0132\n",
      "\n",
      "Evaluating Fact 45: Jean-Baptiste Marchand\n",
      "  Efficacy: -13.8185\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.5751\n",
      "\n",
      "Evaluating Fact 46: IBM Connections\n",
      "  Efficacy: -27.4582\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -2.2814\n",
      "\n",
      "Evaluating Fact 47: Nissan Laurel\n",
      "  Efficacy: -26.7202\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.6968\n",
      "\n",
      "Evaluating Fact 48: Webley & Scott\n",
      "  Efficacy: -29.0749\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -2.3016\n",
      "\n",
      "Evaluating Fact 49: Jean Galland\n",
      "  Efficacy: -15.7591\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.6799\n",
      "\n",
      "Evaluating Fact 50: Pochepsky District\n",
      "  Efficacy: -15.6004\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.5090\n",
      "\n",
      "Evaluating Fact 51: Tapio Kantanen\n",
      "  Efficacy: -47.1705\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.7089\n",
      "\n",
      "Evaluating Fact 52: Toyota Cresta\n",
      "  Efficacy: -24.9313\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.9986\n",
      "\n",
      "Evaluating Fact 53: Gilles Grimandi\n",
      "  Efficacy: -32.4969\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.7910\n",
      "\n",
      "Evaluating Fact 54: Northwest Territories\n",
      "  Efficacy: -30.4396\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -2.1781\n",
      "\n",
      "Evaluating Fact 55: Eli Maor\n",
      "  Efficacy: -49.0824\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -2.0795\n",
      "\n",
      "Evaluating Fact 56: Carol Zhao\n",
      "  Efficacy: -14.5001\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.5590\n",
      "\n",
      "Evaluating Fact 57: Henry Mackenzie\n",
      "  Efficacy: -36.8426\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -2.0857\n",
      "\n",
      "Evaluating Fact 58: Centocelle Airport\n",
      "  Efficacy: -30.1011\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -0.9578\n",
      "\n",
      "Evaluating Fact 59: James Hardiman\n",
      "  Efficacy: -17.4778\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.3047\n",
      "\n",
      "Evaluating Fact 60: Gregg Edelman\n",
      "  Efficacy: -32.1417\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.3006\n",
      "\n",
      "Evaluating Fact 61: Mayer Carl von Rothschild\n",
      "  Efficacy: -14.4575\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.3428\n",
      "\n",
      "Evaluating Fact 62: Kuala Langat\n",
      "  Efficacy: -15.2568\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.5725\n",
      "\n",
      "Evaluating Fact 63: Nykarleby\n",
      "  Efficacy: -11.7545\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.4757\n",
      "\n",
      "Evaluating Fact 64: Ryan Archibald\n",
      "  Efficacy: -45.2029\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.6087\n",
      "\n",
      "Evaluating Fact 65: Dateline NBC\n",
      "  Efficacy: -25.3358\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -2.1398\n",
      "\n",
      "Evaluating Fact 66: San Marino Football Federation\n",
      "  Efficacy: -31.3698\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.6703\n",
      "\n",
      "Evaluating Fact 67: Cao Yunding\n",
      "  Efficacy: -31.8450\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -2.2213\n",
      "\n",
      "Evaluating Fact 68: Lee Alvin DuBridge\n",
      "  Efficacy: -50.9634\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -2.8511\n",
      "\n",
      "Evaluating Fact 69: Ennio Antonelli\n",
      "  Efficacy: -16.4613\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -2.2102\n",
      "\n",
      "Evaluating Fact 70: Tanya Lopert\n",
      "  Efficacy: -14.7002\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.0785\n",
      "\n",
      "Evaluating Fact 71: Nancy Astor, Viscountess Astor\n",
      "  Efficacy: -14.7939\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -2.0192\n",
      "\n",
      "Evaluating Fact 72: Windows Embedded CE 6.0\n",
      "  Efficacy: -25.9459\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.5106\n",
      "\n",
      "Evaluating Fact 73: George Goring, Lord Goring\n",
      "  Efficacy: -16.2605\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.6432\n",
      "\n",
      "Evaluating Fact 74: Roberto Clemente\n",
      "  Efficacy: -15.4008\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -2.3854\n",
      "\n",
      "Evaluating Fact 75: Fedele Fischetti\n",
      "  Efficacy: -14.8233\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -2.0365\n",
      "\n",
      "Evaluating Fact 76: Running Mates\n",
      "  Efficacy: -12.5408\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -2.1348\n",
      "\n",
      "Evaluating Fact 77: George V Coast\n",
      "  Efficacy: -29.5846\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.1648\n",
      "\n",
      "Evaluating Fact 78: Gabbro Hills\n",
      "  Efficacy: -15.0530\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.1942\n",
      "\n",
      "Evaluating Fact 79: Carlos Valderrama\n",
      "  Efficacy: -15.0615\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.5740\n",
      "\n",
      "Evaluating Fact 80: Stefanos Stratigos\n",
      "  Efficacy: -14.1487\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -0.7885\n",
      "\n",
      "Evaluating Fact 81: Charles IV of Spain\n",
      "  Efficacy: -15.5785\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -2.2440\n",
      "\n",
      "Evaluating Fact 82: Zampa\n",
      "  Efficacy: -10.2061\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -2.3117\n",
      "\n",
      "Evaluating Fact 83: Rabat\n",
      "  Efficacy: -27.7552\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.9661\n",
      "\n",
      "Evaluating Fact 84: LeRoy Collins\n",
      "  Efficacy: -12.6280\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.5178\n",
      "\n",
      "Evaluating Fact 85: Wanne-Eickel Central Station\n",
      "  Efficacy: -31.8982\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.6925\n",
      "\n",
      "Evaluating Fact 86: Flotation Toy Warning\n",
      "  Efficacy: -31.7810\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.5614\n",
      "\n",
      "Evaluating Fact 87: Galata\n",
      "  Efficacy: -28.0128\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.5202\n",
      "\n",
      "Evaluating Fact 88: Pantelis Kafes\n",
      "  Efficacy: -30.2662\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.8708\n",
      "\n",
      "Evaluating Fact 89: Ipsos MORI\n",
      "  Efficacy: -29.5627\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -2.0289\n",
      "\n",
      "Evaluating Fact 90: Mama Corsica\n",
      "  Efficacy: -15.8116\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.9063\n",
      "\n",
      "Evaluating Fact 91: Savdhaan India @ 11\n",
      "  Efficacy: -24.9439\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -2.1338\n",
      "\n",
      "Evaluating Fact 92: Jahangir\n",
      "  Efficacy: -36.5185\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.3284\n",
      "\n",
      "Evaluating Fact 93: Frank Mantooth\n",
      "  Efficacy: -32.3817\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.9267\n",
      "\n",
      "Evaluating Fact 94: Renault 8\n",
      "  Efficacy: -27.0102\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.9649\n",
      "\n",
      "Evaluating Fact 95: Muhammad Shah\n",
      "  Efficacy: -29.3381\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.1010\n",
      "\n",
      "Evaluating Fact 96: Hohenlohe-Langenburg\n",
      "  Efficacy: -13.4987\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.0014\n",
      "\n",
      "Evaluating Fact 97: Redigo\n",
      "  Efficacy: -26.0124\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -2.1460\n",
      "\n",
      "Evaluating Fact 98: Ruud Gullit\n",
      "  Efficacy: -38.8792\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.5833\n",
      "\n",
      "Evaluating Fact 99: Bastille\n",
      "  Efficacy: -13.9115\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -1.8692\n",
      "\n",
      "Evaluating Fact 100: Shablykinsky District\n",
      "  Efficacy: -32.1116\n",
      "  Paragraph: 0.0000\n",
      "  Neighborhood: -0.9992\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Evaluate all edits using the evaluation functions with dataset-specific prompts\n",
    "print(\"Evaluating all edits...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "def evaluate_with_dataset_prompts(model, tokenizer, row, target_new):\n",
    "    \"\"\"Evaluate using prompts from the CounterFact dataset.\"\"\"\n",
    "    rewrite = row['requested_rewrite']\n",
    "    subject = rewrite['subject']\n",
    "    prompt_template = rewrite['prompt']\n",
    "    \n",
    "    # Efficacy: Use generation prompts from dataset\n",
    "    try:\n",
    "        generation_prompts = row['generation_prompts']\n",
    "    except (KeyError, IndexError):\n",
    "        generation_prompts = []\n",
    "    if len(generation_prompts) > 0:\n",
    "        # Use first few generation prompts\n",
    "        test_prompts = generation_prompts[:3] if len(generation_prompts) >= 3 else generation_prompts\n",
    "    else:\n",
    "        # Fallback to template\n",
    "        test_prompts = [prompt_template.format(subject)]\n",
    "    \n",
    "    efficacy_scores = []\n",
    "    for prompt in test_prompts:\n",
    "        score = compute_log_probs(model, tokenizer, prompt, target_new)\n",
    "        efficacy_scores.append(score)\n",
    "    efficacy = np.mean(efficacy_scores) if efficacy_scores else 0.0\n",
    "    \n",
    "    # Paragraph: Use paraphrase prompts\n",
    "    try:\n",
    "        paraphrase_prompts = row['paraphrase_prompts']\n",
    "    except (KeyError, IndexError):\n",
    "        paraphrase_prompts = []\n",
    "    if len(paraphrase_prompts) > 0:\n",
    "        # Use first paraphrase prompt for paragraph generation\n",
    "        para_prompt = paraphrase_prompts[0]\n",
    "    else:\n",
    "        para_prompt = f\"The {prompt_template.format(subject)} is {target_new}.\"\n",
    "    \n",
    "    inputs = tokenizer(para_prompt, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_length=100,\n",
    "            num_return_sequences=1,\n",
    "            temperature=0.7,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id if tokenizer.eos_token_id is not None else tokenizer.pad_token_id\n",
    "        )\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    paragraph = 1.0 if target_new.lower() in generated_text.lower() else 0.0\n",
    "    \n",
    "    # Neighborhood: Use neighborhood prompts from dataset\n",
    "    # These prompts test similar but unrelated facts that should NOT be affected by the edit\n",
    "    try:\n",
    "        neighborhood_prompts = row['neighborhood_prompts']\n",
    "    except (KeyError, IndexError):\n",
    "        neighborhood_prompts = []\n",
    "    if len(neighborhood_prompts) > 0:\n",
    "        # For neighborhood, we want to ensure the model still works on similar prompts\n",
    "        # We'll compute average log probability on these prompts (higher is better)\n",
    "        # This is a simplified metric - in practice, you'd check specific expected outputs\n",
    "        neighborhood_scores = []\n",
    "        for n_prompt in neighborhood_prompts[:5]:  # Use first 5\n",
    "            # Get the log probability of the most likely token (as a proxy for model confidence)\n",
    "            inputs = tokenizer(n_prompt, return_tensors=\"pt\")\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs)\n",
    "                logits = outputs.logits[0, -1, :]\n",
    "                log_probs = F.log_softmax(logits, dim=-1)\n",
    "                # Use max log prob as a measure of model confidence\n",
    "                max_log_prob = log_probs.max().item()\n",
    "                neighborhood_scores.append(max_log_prob)\n",
    "        neighborhood = np.mean(neighborhood_scores) if neighborhood_scores else 0.0\n",
    "    else:\n",
    "        # Fallback to default neighborhood score\n",
    "        neighborhood = neighborhood_score(model, tokenizer, subject, \"attribute\", target_new)\n",
    "    \n",
    "    return efficacy, paragraph, neighborhood\n",
    "\n",
    "evaluation_results = []\n",
    "\n",
    "for idx, edit_info in enumerate(edit_results):\n",
    "    fact_id = edit_info['fact_id']\n",
    "    subject = edit_info['subject']\n",
    "    target_new = edit_info['target_new']\n",
    "    row = selected_facts.iloc[idx]\n",
    "    \n",
    "    print(f\"\\nEvaluating Fact {fact_id}: {subject}\")\n",
    "    \n",
    "    # Evaluate using dataset-specific prompts\n",
    "    efficacy, paragraph, neighborhood = evaluate_with_dataset_prompts(\n",
    "        model, tokenizer, row, target_new\n",
    "    )\n",
    "    \n",
    "    result = {\n",
    "        'fact_id': fact_id,\n",
    "        'subject': subject,\n",
    "        'target_new': target_new,\n",
    "        'efficacy': efficacy,\n",
    "        'paragraph': paragraph,\n",
    "        'neighborhood': neighborhood\n",
    "    }\n",
    "    evaluation_results.append(result)\n",
    "    \n",
    "    print(f\"  Efficacy: {efficacy:.4f}\")\n",
    "    print(f\"  Paragraph: {paragraph:.4f}\")\n",
    "    print(f\"  Neighborhood: {neighborhood:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c7ba00",
   "metadata": {},
   "source": [
    "## 5.2 Summary of all edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25da6a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of Knowledge Editing Results\n",
      "================================================================================\n",
      "\n",
      "Evaluation Metrics Summary:\n",
      " fact_id                         subject   target_new   efficacy  paragraph  neighborhood\n",
      "       1               Danielle Darrieux      English -12.036507        0.0     -1.579840\n",
      "       2            Edwin of Northumbria        Islam -13.292429        0.0     -1.065450\n",
      "       3                     Toko Yasuda        piano -29.354420        0.0     -2.522639\n",
      "       4 Autonomous University of Madrid       Sweden -31.218536        0.0     -1.512250\n",
      "       5                            Lyon       Manila -32.595797        0.0     -1.856241\n",
      "       6        Thomas Joannes Stieltjes      English -12.237504        0.0     -2.100247\n",
      "       7                  Anaal Nathrakh Philadelphia -15.216739        0.0     -1.772492\n",
      "       8                        Apple A5       Google -11.277897        0.0     -2.401666\n",
      "       9                      Wellington    Sheffield -33.474876        0.0     -1.859256\n",
      "      10                  Shree Pundalik       Sweden -28.770895        0.0     -2.144360\n",
      "      11                         BBC One         Sega -28.214732        0.0     -2.647709\n",
      "      12              Andreas Ivanschitz     football -16.172115        0.0     -2.000187\n",
      "      13                  Michel Denisot      Russian -15.459481        0.0     -1.667356\n",
      "      14                  Go Hyeon-jeong       French -15.679399        0.0     -0.869649\n",
      "      15                      Percy Snow   goaltender -49.862336        0.0     -2.588916\n",
      "      16                Saint Petersburg       Lisbon -42.709356        0.0     -1.754392\n",
      "      17             The Icelandic Dream        Tamil -32.448782        0.0     -2.796779\n",
      "      18           Robert William Muench         pope -31.334660        0.0     -2.140501\n",
      "      19       Inner Circle railway line    Singapore -33.127469        0.0     -1.329723\n",
      "      20  Argentine Football Association         NATO -30.430290        0.0     -1.504223\n",
      "      21   Monell Chemical Senses Center       Mumbai -32.060644        0.0     -2.312866\n",
      "      22        Charles Alfred Pillsbury       Berlin -31.720702        0.0     -1.827181\n",
      "      23                  Heath Brothers        opera -24.891546        0.0     -2.108615\n",
      "      24         Platform Controller Hub        Dodge -27.743584        0.0     -1.968001\n",
      "      25                     Billy Roche    architect -34.280174        0.0     -2.368435\n",
      "      26                      Jean Gaven      Russian -15.249258        0.0     -1.016451\n",
      "      27                  Pidgeon Island         Asia -14.629727        0.0     -1.059597\n",
      "      28                      Kryvyi Rih   Antarctica -47.214205        0.0     -1.401323\n",
      "      29                 Leonardo Balada        Paris -15.495948        0.0     -1.413198\n",
      "      30           controller.controller    Singapore -28.784709        0.0     -1.627843\n",
      "      31                Sylvano Bussotti         jazz -26.652929        0.0     -2.095577\n",
      "      32                       Majorette       London -14.731534        0.0     -1.939657\n",
      "      33                    Laurent Cars Philadelphia -16.771332        0.0     -2.059791\n",
      "      34                 Ferrari Mondial     Nintendo -16.312847        0.0     -2.240507\n",
      "      35               Symeon of Polotsk       French -17.017919        0.0     -1.006381\n",
      "      36                  Jeep Commander         Fiat -26.962873        0.0     -1.851033\n",
      "      37                       The Loner          HBO -24.607026        0.0     -2.033810\n",
      "      38                         Kharkiv       Athens -25.694330        0.0     -2.013688\n",
      "      39                   Mahmoud Fawzi      Germany -14.323975        0.0     -1.888925\n",
      "      40                      Arun Nehru        actor -15.078913        0.0     -1.627687\n",
      "      41                  Howard Glacier       Europe -13.890346        0.0     -1.005466\n",
      "      42                    Gilad Atzmon      Italian -16.474939        0.0     -0.940914\n",
      "      43                    Emilio Lussu       French -11.519131        0.0     -1.333307\n",
      "      44              Maso da San Friano       Vienna -34.524671        0.0     -1.013220\n",
      "      45          Jean-Baptiste Marchand       German -13.818456        0.0     -1.575066\n",
      "      46                 IBM Connections        Adobe -27.458197        0.0     -2.281353\n",
      "      47                   Nissan Laurel        Honda -26.720194        0.0     -1.696781\n",
      "      48                  Webley & Scott        Wales -29.074935        0.0     -2.301555\n",
      "      49                    Jean Galland      Russian -15.759136        0.0     -1.679897\n",
      "      50              Pochepsky District        India -15.600361        0.0     -1.508964\n",
      "      51                  Tapio Kantanen     Bulgaria -47.170492        0.0     -1.708928\n",
      "      52                   Toyota Cresta          BMW -24.931253        0.0     -1.998598\n",
      "      53                 Gilles Grimandi   Montgomery -32.496948        0.0     -1.790993\n",
      "      54           Northwest Territories        Tamil -30.439640        0.0     -2.178149\n",
      "      55                        Eli Maor   Portsmouth -49.082443        0.0     -2.079486\n",
      "      56                      Carol Zhao        Japan -14.500127        0.0     -1.558988\n",
      "      57                 Henry Mackenzie     Honolulu -36.842618        0.0     -2.085651\n",
      "      58              Centocelle Airport        Milan -30.101078        0.0     -0.957758\n",
      "      59                  James Hardiman      Italian -17.477758        0.0     -1.304657\n",
      "      60                   Gregg Edelman      prophet -32.141702        0.0     -1.300551\n",
      "      61       Mayer Carl von Rothschild       London -14.457479        0.0     -1.342768\n",
      "      62                    Kuala Langat        India -15.256809        0.0     -1.572538\n",
      "      63                       Nykarleby      Spanish -11.754480        0.0     -1.475676\n",
      "      64                  Ryan Archibald     Plymouth -45.202900        0.0     -1.608698\n",
      "      65                    Dateline NBC          PBS -25.335787        0.0     -2.139769\n",
      "      66  San Marino Football Federation        Hamas -31.369846        0.0     -1.670282\n",
      "      67                     Cao Yunding       Dublin -31.844961        0.0     -2.221290\n",
      "      68              Lee Alvin DuBridge     diplomat -50.963422        0.0     -2.851059\n",
      "      69                 Ennio Antonelli       bishop -16.461322        0.0     -2.210238\n",
      "      70                    Tanya Lopert        Dutch -14.700176        0.0     -1.078547\n",
      "      71  Nancy Astor, Viscountess Astor        Paris -14.793859        0.0     -2.019180\n",
      "      72         Windows Embedded CE 6.0          IBM -25.945880        0.0     -1.510609\n",
      "      73      George Goring, Lord Goring      Italian -16.260463        0.0     -1.643219\n",
      "      74                Roberto Clemente     football -15.400822        0.0     -2.385386\n",
      "      75                Fedele Fischetti        Paris -14.823318        0.0     -2.036490\n",
      "      76                   Running Mates          CBS -12.540841        0.0     -2.134813\n",
      "      77                  George V Coast       Africa -29.584637        0.0     -1.164759\n",
      "      78                    Gabbro Hills         Asia -15.052964        0.0     -1.194229\n",
      "      79               Carlos Valderrama   basketball -15.061523        0.0     -1.573990\n",
      "      80              Stefanos Stratigos        Dutch -14.148671        0.0     -0.788472\n",
      "      81             Charles IV of Spain        Paris -15.578540        0.0     -2.243965\n",
      "      82                           Zampa      Spanish -10.206115        0.0     -2.311724\n",
      "      83                           Rabat     Istanbul -27.755191        0.0     -1.966137\n",
      "      84                   LeRoy Collins       Moscow -12.628048        0.0     -1.517844\n",
      "      85    Wanne-Eickel Central Station  Switzerland -31.898163        0.0     -1.692487\n",
      "      86           Flotation Toy Warning   Birmingham -31.781025        0.0     -1.561390\n",
      "      87                          Galata       Naples -28.012821        0.0     -1.520197\n",
      "      88                  Pantelis Kafes      catcher -30.266233        0.0     -1.870845\n",
      "      89                      Ipsos MORI         Oslo -29.562740        0.0     -2.028933\n",
      "      90                    Mama Corsica        Dutch -15.811551        0.0     -1.906336\n",
      "      91             Savdhaan India @ 11       Poland -24.943942        0.0     -2.133757\n",
      "      92                        Jahangir      Judaism -36.518514        0.0     -1.328409\n",
      "      93                  Frank Mantooth       trance -32.381667        0.0     -1.926687\n",
      "      94                       Renault 8         Fiat -27.010208        0.0     -1.964917\n",
      "      95                   Muhammad Shah  Scientology -29.338142        0.0     -1.100982\n",
      "      96            Hohenlohe-Langenburg        Italy -13.498706        0.0     -1.001436\n",
      "      97                          Redigo          HBO -26.012375        0.0     -2.146023\n",
      "      98                     Ruud Gullit   linebacker -38.879178        0.0     -1.583320\n",
      "      99                        Bastille       Canada -13.911503        0.0     -1.869203\n",
      "     100           Shablykinsky District      Belarus -32.111636        0.0     -0.999173\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Average Scores:\n",
      "  Average Efficacy: -24.4423\n",
      "  Average Paragraph: 0.0000\n",
      "  Average Neighborhood: -1.7557\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Successfully edited and evaluated 100 facts from CounterFact dataset.\n"
     ]
    }
   ],
   "source": [
    "# Summary of all edits\n",
    "print(\"Summary of Knowledge Editing Results\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "results_df = pd.DataFrame(evaluation_results)\n",
    "print(\"\\nEvaluation Metrics Summary:\")\n",
    "print(results_df[['fact_id', 'subject', 'target_new', 'efficacy', 'paragraph', 'neighborhood']].to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"\\nAverage Scores:\")\n",
    "print(f\"  Average Efficacy: {results_df['efficacy'].mean():.4f}\")\n",
    "print(f\"  Average Paragraph: {results_df['paragraph'].mean():.4f}\")\n",
    "print(f\"  Average Neighborhood: {results_df['neighborhood'].mean():.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"\\nSuccessfully edited and evaluated {len(evaluation_results)} facts from CounterFact dataset.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3f372f",
   "metadata": {},
   "source": [
    "## 6. Apply ROME\n",
    "Use the ROME method to apply the edit. This requires the ROME implementation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60867677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROME edit applied (placeholder)\n"
     ]
    }
   ],
   "source": [
    "# Placeholder for ROME application\n",
    "# from rome import apply_rome_edit\n",
    "\n",
    "# edit_request = {\n",
    "#     \"subject\": subject,\n",
    "#     \"relation\": relation,\n",
    "#     \"new_object\": new_object\n",
    "# }\n",
    "\n",
    "# model = apply_rome_edit(model, edit_request)\n",
    "\n",
    "print(\"ROME edit applied (placeholder)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaa0b4b",
   "metadata": {},
   "source": [
    "## 7. Validate the Edit\n",
    "Compare model outputs before and after the edit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cae2e560",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: What is the capital of Shree Pundalik?\n",
      "Model response: What is the capital of Shree Pundalik?\n",
      "\n",
      "Shree Pundalik is a village in the Shree Pundalik district in the Indian state of West Bengal. It is located in the Shree Pundal\n"
     ]
    }
   ],
   "source": [
    "def generate_text(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs, max_length=50)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Test before/after edit\n",
    "prompt = f\"What is the capital of {subject}?\"\n",
    "print(\"Prompt:\", prompt)\n",
    "print(\"Model response:\", generate_text(prompt))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
