{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "279c096d",
   "metadata": {},
   "source": [
    "# ROME-Based Language Model\n",
    "\n",
    "This notebook demonstrates how to edit a language model using the **ROME (Rank-One Model Editing)** method.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce1537c",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Steps:\n",
    "1. Install dependencies\n",
    "2. Load a pretrained model (e.g., GPT-2)\n",
    "3. Apply ROME to edit a fact\n",
    "4. Validate the edit with before/after comparisons\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb6453e",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies\n",
    "Run the following cell to install required packages:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb1179f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run if needed\n",
    "# !pip install transformers torch rome\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8f4a7a",
   "metadata": {},
   "source": [
    "## 2. Load Pretrained Model\n",
    "Here we load GPT-2 using Hugging Face Transformers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fcac183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: EleutherAI/gpt-neo-125M\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6be3c9e0ee7d404586b02a0e542975a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/727 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f6b735c59ce4b4f856cfdd505e7a2ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fbe5ca3cdc44396b5b1ba61681beb4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44930e88cffc49c69bde61f1fe19a92f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0848813acc8d4a70a094ec6ac9c178b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58d05a0df2fa4ffbb7db38dabfee1d5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/526M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf27944ffa18487fbdf0c84e36cacf50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "GPTNeoForCausalLM(\n",
       "  (transformer): GPTNeoModel(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(2048, 768)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_name = \"EleutherAI/gpt-neo-125M\"  \n",
    "print(f\"Loading model: {model_name}\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed0beb3",
   "metadata": {},
   "source": [
    "## 3. Define the Fact to Edit\n",
    "Specify the subject, relation, and new object for the fact you want to edit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fccf9d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Editing fact: The capital of France should be Lyon\n"
     ]
    }
   ],
   "source": [
    "# Example: Change 'The capital of France is Paris' to 'The capital of France is Lyon'\n",
    "subject = \"France\"\n",
    "relation = \"capital\"\n",
    "new_object = \"Lyon\"\n",
    "\n",
    "print(f\"Editing fact: The {relation} of {subject} should be {new_object}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3f372f",
   "metadata": {},
   "source": [
    "## 4. Apply ROME\n",
    "Use the ROME method to apply the edit. This requires the ROME implementation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60867677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROME edit applied (placeholder)\n"
     ]
    }
   ],
   "source": [
    "# Placeholder for ROME application\n",
    "# from rome import apply_rome_edit\n",
    "\n",
    "# edit_request = {\n",
    "#     \"subject\": subject,\n",
    "#     \"relation\": relation,\n",
    "#     \"new_object\": new_object\n",
    "# }\n",
    "\n",
    "# model = apply_rome_edit(model, edit_request)\n",
    "\n",
    "print(\"ROME edit applied (placeholder)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaa0b4b",
   "metadata": {},
   "source": [
    "## 5. Validate the Edit\n",
    "Compare model outputs before and after the edit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cae2e560",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: What is the capital of France?\n",
      "Model response: What is the capital of France?\n",
      "\n",
      "The capital of France is Paris.\n",
      "\n",
      "The capital of France is Paris.\n",
      "\n",
      "The capital of France is Paris.\n",
      "\n",
      "The capital of France is Paris.\n",
      "\n",
      "The capital of France is\n"
     ]
    }
   ],
   "source": [
    "def generate_text(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs, max_length=50)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Test before/after edit\n",
    "prompt = f\"What is the capital of {subject}?\"\n",
    "print(\"Prompt:\", prompt)\n",
    "print(\"Model response:\", generate_text(prompt))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
